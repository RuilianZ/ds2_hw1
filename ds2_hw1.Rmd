---
title: "Home Work 2 for Data Science II"
author: "Roxy Zhang (rz2570)"
date: "2/12/2022"
output: github_document
---

### Setup and import data

```{r, message = FALSE}
library(tidyverse)
library(caret)
library(corrplot)
library(leaps)


```

```{r, message = FALSE}
train_df = 
  read_csv("data/housing_training.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()

test_df = 
  read_csv("data/housing_test.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()

dim(train_df)
table(sapply(train_df[ , -1], class)) %>% 
  knitr::kable()

dim(test_df)
table(sapply(test_df[ , -1], class)) %>% 
  knitr::kable()
```

* We want to predict outcome variable `sale_price` by selecting predictors from `r ncol(train_df)` variables, among which there are 4 categorical variables and 21 continuous variables.   
* There are `r nrow(train_df)` data in training data and `r nrow(test_df)` in test data.  


### Data preparation

For the convenience of fitting models, we want to create vectors and matrices in advance:

```{r}
train_x <- model.matrix(sale_price ~ ., train_df)[ ,-1]
train_y <- train_df$sale_price
test_x <- model.matrix(sale_price ~ ., test_df)[ , -1]
test_y <- test_df$sale_price
test_all <- model.matrix(sale_price ~ ., test_df)
```

In linear regression, correlation among variables can cause large variance and make interpretation harder.  
So we want to have a look and the potential correlation among predictors:

```{r}
corrplot(
  cor(train_x), 
  method = "circle",
  type = "full",
  tl.cex = .5, 
  tl.col = "darkblue")
```

* From the plot above, we can see some positive correlations in the upright corner among some area-related predictors such as `gr_liv_area` and `second_flr_sf`, and also negative correlations among categorical variables such as `exter_qualTypical` and `kitchen_qualTypical`.  
* To reduce the influence of correlation, we may want to reduce the number of predictors using best subset model selection.  

```{r}
lm_subsets <- regsubsets(sale_price ~ .,
                         data = train_df,
                         method = "exhaustive",
                         nbest = 6)

plot(lm_subsets, scale = "bic")

# Look at actual numbers of predictors
# summary(lm_subsets)
```
 
* The plot above gives us a sense of model selsction. Hoever, we will stick to using all the predictors in this assignment.


## Least Squares

Fit a linear model using least squares on the training data. Is there any potential disadvantage of this model?

### Model fitting

```{r, warning = FALSE}
set.seed(2570)

# Specify resampling method
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

# Fit a linear model using caret
lm_fit <- train(sale_price ~ .,
                data = train_df,
                method = "lm",
                preProcess = c("center", "scale"),
                trControl = ctrl)
 
# Extract coefficiencts
round(lm_fit$finalModel$coefficients, 3) %>% 
  knitr::kable()

# Calculate mean training RMSE
mean(lm_fit$resample$RMSE)
```

### Make prediction

```{r}
# Make prediction on test data
lm_predict <- predict(lm_fit, newdata = test_df)

# Calculate test RMSE
RMSE(lm_predict, test_df$sale_price)
```

**Potential Disadvantage:**  
* The model contains too many predictors, which is hard for interpretation.    
* As seen above, there are correlations among predictors, which may lead to: 1. higher variance and RMSE 2. less prediction accuracy 3. difficulty for interpretation  
* Due to the nature of its modeling method, Least Squares is sensitive to outliers.  
* Large data set is necessary in order to obtain reliable results. Our sample in this case might not be large enough.  


## Lasso

Fit a lasso model on the training data and report the test error. When the 1SE rule is applied, how many predictors are included in the model?

### Model fitting

```{r}
set.seed(2570)

# Specify resampling method for 1SE
ctrl_1se = trainControl(method = "repeatedcv", number = 10, repeats = 5, selectionFunction = "oneSE")

# Fit a lasso model using caret
# The fitted model is a glemnet object, so we need to use matrix as input
lasso_fit <- train(x = train_x, 
                   y = train_y,
                   method = "glmnet",
                   preProcess = c("center", "scale"),
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(5, -1, length = 100))),
                   trControl = ctrl_1se)

# Plot RMSE against lambda
plot(lasso_fit, xTrans = log)

# Extract optimum lambda
lasso_fit$bestTune

# Extract coefficiencts
as.matrix(round(coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda), 3)) %>% 
  knitr::kable()
```

* From the fitted lasso model, we can see that the opitmum lambda chosen is `r lasso_fit$bestTune$lambda`

### Make prediction

```{r}
set.seed(2570)

# Make prediction on test data
lasso_predict <- predict(lasso_fit, newdata = test_all)

# Calculate test RMSE
RMSE(lasso_predict, test_df$sale_price)
```

* The test RMSE is `r round(RMSE(lasso_predict, test_df$sale_price), 2)`.  
* When the 1SE rule is applied, there are `r data.frame(as.matrix(coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda))) %>% filter(s1 != 0) %>% nrow()` predictors included in the model.  


## Elastic Net

Fit an elastic net model on the training data. Report the selected tuning parameters and the test error.

### Model fitting

```{r}

```

